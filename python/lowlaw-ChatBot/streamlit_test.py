import streamlit as st
from sentence_transformers import SentenceTransformer, util
from elasticsearch import Elasticsearch
from PIL import Image
import re

es_cloud_id = ""
es_username = ""
es_pw = ""

es = Elasticsearch(cloud_id=es_cloud_id, basic_auth=(es_username, es_pw))

if "messages" not in st.session_state:
    st.session_state.messages = []
if "user_input" not in st.session_state:
    st.session_state.user_input = None

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.write(message["content"])


@st.cache_data() # st ìºì‹± (ë¡œì»¬ìºì‹œì— ì €ì¥)

def cached_model():
    model = SentenceTransformer('jhgan/ko-sroberta-multitask')
    return model

def load_image(img_file): # st ì´ë¯¸ì§€ ë¶ˆëŸ¬ì˜¤ê¸° í•¨ìˆ˜
    img = Image.open(img_file)
    return img
model = cached_model() # sentenceBERT ëª¨ë¸

logo_file = '../image/lowlaw.png' # ë¡œê³  ì´ë¯¸ì§€ íŒŒì¼ê²½ë¡œ
logo_img = load_image(logo_file) # ë¡œê³  ì´ë¯¸ì§€ ê°€ì ¸ì˜´

sumung_file = '../image/lowlaw_sumung.png' # ìˆ˜ë­‰ì´ ì´ë¯¸ì§€ íŒŒì¼ê²½ë¡œ
sumung_img = load_image(sumung_file) # ìˆ˜ë­‰ì´ ì´ë¯¸ì§€ ê°€ì ¸ì˜´

# sidebar
with st.sidebar:
    st.image(logo_img, width = 300, output_format = "PNG")
    st.title("ì„ëŒ€ì°¨ ë¶„ìŸ ë²•ë¥  ì¡°ì–¸ ì„œë¹„ìŠ¤")
    st.divider()

# Streamlit ì•± ì‹œì‘
st.header("LOWLAW :scales: AI ìƒí™©ë¶„ì„")

# ChatBotì˜ í™˜ì˜ì¸ì‚¬
with st.chat_message("assistant"):
    st.write("ì•ˆë…•í•˜ì„¸ìš”! LOWLAWì— ì˜¤ì‹  ê²ƒì„ í™˜ì˜í•©ë‹ˆë‹¤:wave:")
    st.write("ë‚´ê°€ ì–´ë–¤ ìƒí™©ì¸ì§€ íŒŒì•…í•˜ê³  ì–´ë–»ê²Œ í•´ê²°í• ì§€ ê¶ê¸ˆí•˜ë‹¤ë©´ LOWLAWì™€ ëŒ€í™”í•˜ë©´ì„œ í•´ê²°í•´ë³´ì„¸ìš”")
query = {
    "query": {
        "match_all": {}
    },
    "_source": ["question","answer","law", "prec", "embedding"]
}

response = es.search(index="legal_qa", body=query, size=100)


# ë¬¸ì¥ë²¡í„° ê³„ì‚°


# Elasticsearchì—ì„œ embedding í•„ë“œ ê°’ ê²€ìƒ‰

#ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ ì €ì¥
sources = {}


# ê°€ì¥ ë†’ì€ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê°’ ì´ˆê¸°í™”
max_cosine_similarity = -1
best_answer = ""



def button_law() :
    st.session_state.messages.append({"role" : "assistant", "content" : "ë€¨"})
def button_prec() :
    st.session_state.messages.append({"role" : "assistant", "content" : "í“¨"})  

def addChatBot():
    source = sources["source"]
    best_answer = source["answer"]
    related_law = source.get("law", None) # í•„ë“œì— ë°ì´í„°ê°€ ì¡´ì¬í•˜ë©´ law ê°’ì„ ê°€ì ¸ì˜¤ê³  ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜
    related_prec = source.get("prec", None)

    best_answer = re.sub(r'\((.*?)\)', lambda x: x.group(0).replace('.', ' '), best_answer)
    st.session_state.messages.append({"role" : "assistant", "content" : best_answer})

    if related_law:
        related_law_list = related_law.split(",")
        st.markdown(f"**:red[ì°¸ì¡°ë²•ë ¹]** :scales:")
        for law in related_law_list: # ì°¸ì¡°íŒë¡€ ë¦¬ìŠ¤íŠ¸ ì•ˆì— ìˆëŠ” ë‚´ìš© ê°ê° ë²„íŠ¼ìœ¼ë¡œ ì¶œë ¥  
            st.session_state.messages.append({"role": "ğŸ“–", "content": f"**:red[ì°¸ì¡°ë²•ë ¹] {st.button(law.strip(),on_click=lambda:button_law())}**"})
            # st.session_state.messages.append({"role": "ğŸ“–", "content": f"**:red[ì°¸ì¡°ë²•ë ¹] {law.strip()}**"})

    if related_prec: # ë§Œì•½ ì°¸ì¡°íŒë¡€ê°€ ìˆë‹¤ë©´
        related_prec_list = related_prec.split(",")  # ','ë¡œ êµ¬ë¶„í•˜ì—¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        st.markdown(f"**:red[ì°¸ì¡°íŒë¡€]** :scales:")
        for prec in related_prec_list: # ì°¸ì¡°íŒë¡€ ë¦¬ìŠ¤íŠ¸ ì•ˆì— ìˆëŠ” ë‚´ìš© ê°ê° ë²„íŠ¼ìœ¼ë¡œ ì¶œë ¥  
            st.session_state.messages.append({"role": "âš–ï¸", "content": f"**:red[ì°¸ì¡°íŒë¡€] {st.button(prec.strip(),on_click=lambda:button_prec())}**"})
            # st.session_state.messages.append({"role": "âš–ï¸", "content": f"**:red[ì°¸ì¡°íŒë¡€] {prec.strip()}**"})

def user_submit():
    
    # st.chat_message("user").markdown(user_input)

    # ì‚¬ìš©ìì˜ user_inputì„ chat historyì— append

    for hit in response["hits"]["hits"]:
        doc_embedding = hit["_source"]["embedding"]
    
        # Elasticsearchì—ì„œ ê°€ì ¸ì˜¨ 'embedding' ê°’ì„ ë¬¸ìì—´ì—ì„œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
        doc_embedding = [float(value) for value in doc_embedding.strip("[]").split(", ")]
    
        cosine_similarity = util.pytorch_cos_sim(embeddings, [doc_embedding]).item()
    
        if cosine_similarity > max_cosine_similarity:
            max_cosine_similarity = cosine_similarity
            source = hit["_source"]
            # best_answer = source["answer"]
            # related_law = hit["_source"].get("law", None) # í•„ë“œì— ë°ì´í„°ê°€ ì¡´ì¬í•˜ë©´ law ê°’ì„ ê°€ì ¸ì˜¤ê³  ì¡´ì¬í•˜ì§€ ì•Šìœ¼ë©´ None ë°˜í™˜
            # related_prec = hit["_source"].get("prec", None)
        
        if max_cosine_similarity>0.7:
            sources["source"] = source
            addChatBot()
    else:
        # assistantì˜ ë‹µë³€ chat messageì— ë„ì›Œì£¼ê¸° (0.7 ì´í•˜ì¼ ë•Œ)
        with st.chat_message("assistant"):
            st.markdown("ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”:cry: ìƒí™©ì— ëŒ€í•´ì„œ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”!")
        st.session_state.messages.append({"role" : "assistant", "content" : "ì§ˆë¬¸ì— ëŒ€í•œ ë‹µë³€ì„ ì°¾ì„ ìˆ˜ ì—†ì–´ìš”:cry: ìƒí™©ì— ëŒ€í•´ì„œ ì •í™•íˆ ì…ë ¥í•´ì£¼ì„¸ìš”!" }) # ê°€ì¥ ìœ ì‚¬í•œ ë‹µë³€ append

# ì‚¬ìš©ìì—ê²Œ ë¬¸ì¥ ì…ë ¥ ë°›ê¸°
user_input = st.chat_input(placeholder = "ì–´ë–¤ ìƒí™©ì¸ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”!",on_submit=user_submit())
embeddings = model.encode([user_input])[0] if user_input is not None else None
